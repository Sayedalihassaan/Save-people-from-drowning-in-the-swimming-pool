{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345cd4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 311.7ms\n",
      "Speed: 7.0ms preprocess, 311.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 475.7ms\n",
      "Speed: 10.0ms preprocess, 475.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.2ms\n",
      "Speed: 3.0ms preprocess, 278.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 276.9ms\n",
      "Speed: 8.0ms preprocess, 276.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 247.9ms\n",
      "Speed: 4.0ms preprocess, 247.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 256.9ms\n",
      "Speed: 4.0ms preprocess, 256.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 260.8ms\n",
      "Speed: 3.0ms preprocess, 260.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.8ms\n",
      "Speed: 3.5ms preprocess, 250.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 269.4ms\n",
      "Speed: 3.0ms preprocess, 269.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.8ms\n",
      "Speed: 3.0ms preprocess, 260.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.0ms\n",
      "Speed: 4.5ms preprocess, 237.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 246.0ms\n",
      "Speed: 2.0ms preprocess, 246.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.0ms\n",
      "Speed: 2.0ms preprocess, 264.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 253.0ms\n",
      "Speed: 2.0ms preprocess, 253.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 244.4ms\n",
      "Speed: 2.5ms preprocess, 244.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.0ms\n",
      "Speed: 4.0ms preprocess, 252.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 268.1ms\n",
      "Speed: 3.0ms preprocess, 268.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 259.0ms\n",
      "Speed: 4.0ms preprocess, 259.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 254.0ms\n",
      "Speed: 2.0ms preprocess, 254.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 229.0ms\n",
      "Speed: 3.0ms preprocess, 229.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.0ms\n",
      "Speed: 3.0ms preprocess, 275.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 239.0ms\n",
      "Speed: 2.0ms preprocess, 239.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.4ms\n",
      "Speed: 2.5ms preprocess, 230.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.0ms\n",
      "Speed: 3.0ms preprocess, 230.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 228.0ms\n",
      "Speed: 3.0ms preprocess, 228.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.0ms\n",
      "Speed: 2.5ms preprocess, 230.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.0ms\n",
      "Speed: 3.0ms preprocess, 241.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 251.9ms\n",
      "Speed: 4.1ms preprocess, 251.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 259.0ms\n",
      "Speed: 3.0ms preprocess, 259.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 234.5ms\n",
      "Speed: 4.0ms preprocess, 234.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 224.0ms\n",
      "Speed: 3.0ms preprocess, 224.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 232.6ms\n",
      "Speed: 4.0ms preprocess, 232.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 234.7ms\n",
      "Speed: 2.0ms preprocess, 234.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 240.0ms\n",
      "Speed: 3.0ms preprocess, 240.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.9ms\n",
      "Speed: 2.1ms preprocess, 230.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 234.0ms\n",
      "Speed: 3.0ms preprocess, 234.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 234.0ms\n",
      "Speed: 4.0ms preprocess, 234.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 235.4ms\n",
      "Speed: 2.6ms preprocess, 235.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 234.0ms\n",
      "Speed: 2.0ms preprocess, 234.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 240.0ms\n",
      "Speed: 3.0ms preprocess, 240.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 254.9ms\n",
      "Speed: 4.1ms preprocess, 254.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 289.9ms\n",
      "Speed: 2.0ms preprocess, 289.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.0ms\n",
      "Speed: 2.0ms preprocess, 231.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 225.0ms\n",
      "Speed: 4.0ms preprocess, 225.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 227.0ms\n",
      "Speed: 3.0ms preprocess, 227.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 224.9ms\n",
      "Speed: 2.0ms preprocess, 224.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bird, 225.0ms\n",
      "Speed: 3.0ms preprocess, 225.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bird, 234.9ms\n",
      "Speed: 3.0ms preprocess, 234.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 birds, 244.4ms\n",
      "Speed: 4.5ms preprocess, 244.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.0ms\n",
      "Speed: 4.0ms preprocess, 230.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.6ms\n",
      "Speed: 4.0ms preprocess, 231.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 232.0ms\n",
      "Speed: 2.0ms preprocess, 232.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 232.0ms\n",
      "Speed: 4.1ms preprocess, 232.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.0ms\n",
      "Speed: 3.0ms preprocess, 278.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.9ms\n",
      "Speed: 4.0ms preprocess, 266.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 265.9ms\n",
      "Speed: 2.0ms preprocess, 265.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.3ms\n",
      "Speed: 3.0ms preprocess, 237.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 222.4ms\n",
      "Speed: 5.0ms preprocess, 222.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 227.4ms\n",
      "Speed: 3.0ms preprocess, 227.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 234.7ms\n",
      "Speed: 4.0ms preprocess, 234.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.0ms\n",
      "Speed: 5.0ms preprocess, 230.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 239.9ms\n",
      "Speed: 5.0ms preprocess, 239.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 237.9ms\n",
      "Speed: 3.1ms preprocess, 237.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 227.9ms\n",
      "Speed: 3.0ms preprocess, 227.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 263.9ms\n",
      "Speed: 2.0ms preprocess, 263.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 286.0ms\n",
      "Speed: 3.0ms preprocess, 286.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 surfboard, 242.0ms\n",
      "Speed: 3.0ms preprocess, 242.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 243.0ms\n",
      "Speed: 2.0ms preprocess, 243.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.7ms\n",
      "Speed: 4.0ms preprocess, 241.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 232.6ms\n",
      "Speed: 4.0ms preprocess, 232.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.6ms\n",
      "Speed: 3.0ms preprocess, 237.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 246.9ms\n",
      "Speed: 4.0ms preprocess, 246.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 236.0ms\n",
      "Speed: 3.0ms preprocess, 236.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 232.9ms\n",
      "Speed: 3.0ms preprocess, 232.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 245.8ms\n",
      "Speed: 5.1ms preprocess, 245.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 260.0ms\n",
      "Speed: 2.0ms preprocess, 260.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 surfboard, 247.9ms\n",
      "Speed: 5.1ms preprocess, 247.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 253.0ms\n",
      "Speed: 3.0ms preprocess, 253.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 259.0ms\n",
      "Speed: 3.0ms preprocess, 259.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 257.0ms\n",
      "Speed: 3.0ms preprocess, 257.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 263.0ms\n",
      "Speed: 4.0ms preprocess, 263.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.4ms\n",
      "Speed: 3.0ms preprocess, 255.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 259.0ms\n",
      "Speed: 3.0ms preprocess, 259.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 263.0ms\n",
      "Speed: 3.0ms preprocess, 263.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 254.0ms\n",
      "Speed: 4.0ms preprocess, 254.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 254.5ms\n",
      "Speed: 3.5ms preprocess, 254.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import mediapipe\n",
    "import time\n",
    "import miniaudio\n",
    "from mutagen.mp3 import MP3\n",
    "import os\n",
    "\n",
    "def process_video(path, video_file, audio_file, model_path, classes_file, frame_check=7):\n",
    "    os.chdir(path)\n",
    "\n",
    "    my_pose = mediapipe.solutions.pose\n",
    "    my_drawing = mediapipe.solutions.drawing_utils\n",
    "    pose = my_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "    # Model\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Data\n",
    "    with open(classes_file, \"r\") as df:\n",
    "        classes = df.read().split(\"\\n\")\n",
    "\n",
    "        \n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    from tracker import Tracker\n",
    "    tracker = Tracker()\n",
    "    c = set()\n",
    "\n",
    "    audio = MP3(audio_file)\n",
    "    length = audio.info.length\n",
    "\n",
    "    flags = 0\n",
    "    alarm_triggered = False\n",
    "\n",
    "    def calculate_angle(a, b, c):\n",
    "        a , b , c = np.array(a) , np.array(b) , np.array(c)\n",
    "        \n",
    "        radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "        angle = np.abs(radians * 180 / np.pi)\n",
    "        if angle > 180:\n",
    "            angle = 360 - angle\n",
    "        return angle\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame)\n",
    "        imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(imgRGB)\n",
    "        h, w, c = frame.shape\n",
    "\n",
    "        if result.pose_landmarks:\n",
    "            my_drawing.draw_landmarks(frame, result.pose_landmarks, my_pose.POSE_CONNECTIONS,\n",
    "                                      my_drawing.DrawingSpec((0, 255, 0), 2, 2),\n",
    "                                      my_drawing.DrawingSpec((255, 0, 0), 2, 2))\n",
    "\n",
    "            landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "            L_shoulder = [landmarks[my_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                          landmarks[my_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            L_elbow = [landmarks[my_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                       landmarks[my_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            L_wrist = [landmarks[my_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                       landmarks[my_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "            R_shoulder = [landmarks[my_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                          landmarks[my_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            R_elbow = [landmarks[my_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                       landmarks[my_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            R_wrist = [landmarks[my_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                       landmarks[my_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            l_angle = calculate_angle(L_shoulder, L_elbow, L_wrist)\n",
    "            r_angle = calculate_angle(R_shoulder, R_elbow, R_wrist)\n",
    "            \n",
    "\n",
    "            cv2.putText(frame, str(int(l_angle)), tuple(np.multiply(L_elbow, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 0), 2)\n",
    "            cv2.putText(frame, str(int(r_angle)), tuple(np.multiply(R_elbow, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 0), 2)\n",
    "            \n",
    "\n",
    "            if (L_wrist[1] * h < L_elbow[1] * h < L_shoulder[1] * h and l_angle > 150) or \\\n",
    "            (R_wrist[1] * h < R_elbow[1] * h < R_shoulder[1] * h and r_angle > 150):\n",
    "\n",
    "                flags += 1\n",
    "                if flags >= frame_check and not alarm_triggered:\n",
    "                    cv2.putText(frame, \"Warning!!! Someone Needs Help.\", (20, 75), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 255), 2)\n",
    "                    stream = miniaudio.stream_file(audio_file)\n",
    "                    with miniaudio.PlaybackDevice() as device:\n",
    "                        device.start(stream)\n",
    "                        time.sleep(length)\n",
    "                    alarm_triggered = True\n",
    "\n",
    "        lis = []\n",
    "        for res in results:\n",
    "            for box in res.boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                name = classes[int(box.cls[0])]\n",
    "                if \"person\" in name and box.conf[0] > 0.5:\n",
    "                    lis.append([x1, y1, x2, y2])\n",
    "\n",
    "        bbox_id = tracker.update(lis)\n",
    "        id_list = []\n",
    "        for bb in bbox_id:\n",
    "            x, y, w, h, idd = bb\n",
    "            id_list.append(idd)\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (w, h), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"Number Of Persons is = {str(len(lis))}\", (20, 50), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Person ID Is = {id_list}\", (x, y), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "process_video(\n",
    "    path=r\"D:\\Computer Vision\\Save-people-from-drowning-in-the-swimming-pool-by-mediapipe-and-YOLO-main\\save-people-from-swimming\",\n",
    "    video_file=r\"vid.mp4\",\n",
    "    audio_file=r\"audio.mp3\",\n",
    "    model_path=\"yolov8s.pt\",\n",
    "    classes_file=r\"coco.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f28c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78db2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
